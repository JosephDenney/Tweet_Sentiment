{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Preprocessing Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\josep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\josep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer, TfidfTransformer\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<WordListCorpusReader in 'C:\\\\Users\\\\josep\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>\n",
      "{'onto', 'two', 'be', 'back', 'whereupon', 'we', 'indeed', 'mine', 'move', 'hence', 'your', 'his', \"'ll\", 'at', 'below', 'being', 'well', 'into', 'same', 'seemed', 'they', 'eight', 'yet', 'down', 'less', 'whence', 'more', 'about', 'latter', 'used', 'if', 'then', 'anywhere', 'five', 'all', '‘re', 'cannot', 'alone', 'thereafter', 'something', 'again', '‘s', 'everyone', 'ten', 'whither', 'before', 'just', 'bottom', 'are', 'herself', 'hereby', 'whenever', 'while', 'keep', 'up', 'this', \"'re\", 'could', 'here', 'will', 'my', 'fifty', '‘d', '‘ve', 'whatever', 'was', 'anything', 'last', 'ours', \"'ve\", 'been', 'it', 'yourselves', '‘ll', 'no', 'various', 'behind', 'of', 'please', 'thus', 'themselves', 'even', 'yours', 'go', 'thereupon', 'beforehand', 'former', 'somewhere', 'now', 'whoever', 'or', 'where', 'side', 'as', 'empty', 'there', 'seem', 'whom', 'further', 'becomes', 'above', 'by', 'four', 'seems', 'anyway', '’re', 'everywhere', 'thence', 'third', 're', 'across', 'really', 'with', 'because', 'regarding', 'almost', 'myself', 'see', 'make', 'have', 'eleven', 'everything', 'least', \"'m\", 'though', 'i', 'anyone', 'whether', 'somehow', 'an', 'their', 'many', 'therefore', 'in', 'nine', 'why', 'is', 'during', 'after', 'except', 'whereby', 'ourselves', 'towards', 'always', 'per', 'amount', 'say', 'he', 'noone', 'seeming', 'perhaps', 'those', 'front', 'meanwhile', 'whole', 'and', 'which', 'nothing', 'may', 'whose', 'them', 'anyhow', 'under', 'what', 'unless', 'latterly', 'wherein', 'not', 'quite', 'twelve', 'around', 'take', 'any', 'few', 'done', 'us', 'using', 'others', 'although', 'already', 'becoming', 'but', 'none', 'since', 'sometime', 'made', 'me', 'between', 'often', 'should', 'yourself', 'she', 'through', 'wherever', 'each', 'hereupon', 'give', 'nor', 'nevertheless', 'you', 'thru', 'who', 'does', 'our', 'besides', 'only', 'top', \"n't\", 'part', 'her', 'himself', 'has', 'hers', 'every', 'upon', 'too', '’ll', 'became', 'for', 'within', 'doing', 'own', 'had', 'nowhere', 'never', 'otherwise', 'show', 'nobody', 'beside', 'someone', 'off', 'formerly', 'three', \"'s\", 'namely', 'beyond', 'the', 'against', 'over', 'name', 'twenty', 'still', 'how', 'both', 'put', 'its', 'sixty', 'him', 'serious', 'most', 'either', 'among', 'throughout', 'together', 'ca', 'than', '’d', 'amongst', 'six', 'thereby', 'via', 'afterwards', 'were', 'call', \"'d\", '‘m', 'several', 'other', 'n’t', 'toward', 'much', 'due', 'moreover', 'full', 'one', 'might', '’s', 'hundred', 'without', 'hereafter', 'am', 'these', 'do', 'a', 'enough', 'did', 'must', 'herein', 'that', 'once', 'would', 'out', 'very', 'first', 'next', 'itself', 'some', 'ever', 'mostly', 'else', 'whereafter', 'get', 'from', 'n‘t', 'until', 'fifteen', 'another', 'to', 'such', 'forty', 'neither', 'rather', 'elsewhere', 'along', 'however', 'therein', 'so', 'can', 'sometimes', '’m', 'on', '’ve', 'also', 'whereas', 'when', 'become'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/product_tweets.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion',\n",
       "       'No emotion toward brand or product', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns= {'is_there_an_emotion_directed_at_a_brand_or_product'\n",
    "                         :'Emotion','emotion_in_tweet_is_directed_at': 'Platform'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns= {'tweet_text': 'Tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Platform  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            Emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # want to remove the @'name' in the tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummify = pd.get_dummies(df['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I can't tell</th>\n",
       "      <th>Negative emotion</th>\n",
       "      <th>No emotion toward brand or product</th>\n",
       "      <th>Positive emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I can't tell  Negative emotion  No emotion toward brand or product  \\\n",
       "0             0                 1                                   0   \n",
       "1             0                 0                                   0   \n",
       "2             0                 0                                   0   \n",
       "3             0                 1                                   0   \n",
       "4             0                 0                                   0   \n",
       "\n",
       "   Positive emotion  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 1  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I can't tell                           156\n",
       "Negative emotion                       570\n",
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummify.sum() # class bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Tweet     9092 non-null   object\n",
      " 1   Platform  3291 non-null   object\n",
      " 2   Emotion   9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df = pd.merge(df, df_dummify, how='outer',on=df.index) # ran this code, dummify emotion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9093 entries, 0 to 9092\n",
      "Data columns (total 8 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   key_0                               9093 non-null   int64 \n",
      " 1   Tweet                               9092 non-null   object\n",
      " 2   Platform                            3291 non-null   object\n",
      " 3   Emotion                             9093 non-null   object\n",
      " 4   I can't tell                        9093 non-null   uint8 \n",
      " 5   Negative emotion                    9093 non-null   uint8 \n",
      " 6   No emotion toward brand or product  9093 non-null   uint8 \n",
      " 7   Positive emotion                    9093 non-null   uint8 \n",
      "dtypes: int64(1), object(3), uint8(4)\n",
      "memory usage: 390.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>I can't tell</th>\n",
       "      <th>Negative emotion</th>\n",
       "      <th>No emotion toward brand or product</th>\n",
       "      <th>Positive emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_0                                              Tweet  \\\n",
       "0      0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1      1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2      2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3      3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4      4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "             Platform           Emotion  I can't tell  Negative emotion  \\\n",
       "0              iPhone  Negative emotion             0                 1   \n",
       "1  iPad or iPhone App  Positive emotion             0                 0   \n",
       "2                iPad  Positive emotion             0                 0   \n",
       "3  iPad or iPhone App  Negative emotion             0                 1   \n",
       "4              Google  Positive emotion             0                 0   \n",
       "\n",
       "   No emotion toward brand or product  Positive emotion  \n",
       "0                                   0                 0  \n",
       "1                                   0                 1  \n",
       "2                                   0                 1  \n",
       "3                                   0                 0  \n",
       "4                                   0                 1  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns = {\"I can't tell\": \"Uncertain\", 'Negative emotion': 'Negative'\n",
    "                          , 'No emotion toward brand or product': 'No Emotion'\n",
    "                          , 'Positive emotion':'Positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Uncertain</th>\n",
       "      <th>Negative</th>\n",
       "      <th>No Emotion</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Platform  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            Emotion  Uncertain  Negative  No Emotion  Positive  \n",
       "0  Negative emotion          0         1           0         0  \n",
       "1  Positive emotion          0         0           0         1  \n",
       "2  Positive emotion          0         0           0         1  \n",
       "3  Negative emotion          0         1           0         0  \n",
       "4  Positive emotion          0         0           0         1  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='key_0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.',\n",
       " \"@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\",\n",
       " '@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.',\n",
       " \"@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw\",\n",
       " \"@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)\",\n",
       " '@teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd',\n",
       " nan,\n",
       " '#SXSW is just starting, #CTIA is around the corner and #googleio is only a hop skip and a jump from there, good time to be an #android fan',\n",
       " 'Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB',\n",
       " 'Counting down the days to #sxsw plus strong Canadian dollar means stock up on Apple gear']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(df['Tweet'])\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenz = word_tokenize(','.join(str(v) for v in corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', '@', 'wesley83', 'I', 'have', 'a', '3G', 'iPhone', '.', 'After']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenz[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Stopwords List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = list(nlp.Defaults.stop_words)\n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onto',\n",
       " 'two',\n",
       " 'be',\n",
       " 'back',\n",
       " 'whereupon',\n",
       " 'we',\n",
       " 'indeed',\n",
       " 'mine',\n",
       " 'move',\n",
       " 'hence',\n",
       " 'your',\n",
       " 'his',\n",
       " \"'ll\",\n",
       " 'at',\n",
       " 'below',\n",
       " 'being',\n",
       " 'well',\n",
       " 'into',\n",
       " 'same',\n",
       " 'seemed',\n",
       " 'they',\n",
       " 'eight',\n",
       " 'yet',\n",
       " 'down',\n",
       " 'less',\n",
       " 'whence',\n",
       " 'more',\n",
       " 'about',\n",
       " 'latter',\n",
       " 'used',\n",
       " 'if',\n",
       " 'then',\n",
       " 'anywhere',\n",
       " 'five',\n",
       " 'all',\n",
       " '‘re',\n",
       " 'cannot',\n",
       " 'alone',\n",
       " 'thereafter',\n",
       " 'something',\n",
       " 'again',\n",
       " '‘s',\n",
       " 'everyone',\n",
       " 'ten',\n",
       " 'whither',\n",
       " 'before',\n",
       " 'just',\n",
       " 'bottom',\n",
       " 'are',\n",
       " 'herself',\n",
       " 'hereby',\n",
       " 'whenever',\n",
       " 'while',\n",
       " 'keep',\n",
       " 'up',\n",
       " 'this',\n",
       " \"'re\",\n",
       " 'could',\n",
       " 'here',\n",
       " 'will',\n",
       " 'my',\n",
       " 'fifty',\n",
       " '‘d',\n",
       " '‘ve',\n",
       " 'whatever',\n",
       " 'was',\n",
       " 'anything',\n",
       " 'last',\n",
       " 'ours',\n",
       " \"'ve\",\n",
       " 'been',\n",
       " 'it',\n",
       " 'yourselves',\n",
       " '‘ll',\n",
       " 'no',\n",
       " 'various',\n",
       " 'behind',\n",
       " 'of',\n",
       " 'please',\n",
       " 'thus',\n",
       " 'themselves',\n",
       " 'even',\n",
       " 'yours',\n",
       " 'go',\n",
       " 'thereupon',\n",
       " 'beforehand',\n",
       " 'former',\n",
       " 'somewhere',\n",
       " 'now',\n",
       " 'whoever',\n",
       " 'or',\n",
       " 'where',\n",
       " 'side',\n",
       " 'as',\n",
       " 'empty',\n",
       " 'there',\n",
       " 'seem',\n",
       " 'whom',\n",
       " 'further',\n",
       " 'becomes',\n",
       " 'above',\n",
       " 'by',\n",
       " 'four',\n",
       " 'seems',\n",
       " 'anyway',\n",
       " '’re',\n",
       " 'everywhere',\n",
       " 'thence',\n",
       " 'third',\n",
       " 're',\n",
       " 'across',\n",
       " 'really',\n",
       " 'with',\n",
       " 'because',\n",
       " 'regarding',\n",
       " 'almost',\n",
       " 'myself',\n",
       " 'see',\n",
       " 'make',\n",
       " 'have',\n",
       " 'eleven',\n",
       " 'everything',\n",
       " 'least',\n",
       " \"'m\",\n",
       " 'though',\n",
       " 'i',\n",
       " 'anyone',\n",
       " 'whether',\n",
       " 'somehow',\n",
       " 'an',\n",
       " 'their',\n",
       " 'many',\n",
       " 'therefore',\n",
       " 'in',\n",
       " 'nine',\n",
       " 'why',\n",
       " 'is',\n",
       " 'during',\n",
       " 'after',\n",
       " 'except',\n",
       " 'whereby',\n",
       " 'ourselves',\n",
       " 'towards',\n",
       " 'always',\n",
       " 'per',\n",
       " 'amount',\n",
       " 'say',\n",
       " 'he',\n",
       " 'noone',\n",
       " 'seeming',\n",
       " 'perhaps',\n",
       " 'those',\n",
       " 'front',\n",
       " 'meanwhile',\n",
       " 'whole',\n",
       " 'and',\n",
       " 'which',\n",
       " 'nothing',\n",
       " 'may',\n",
       " 'whose',\n",
       " 'them',\n",
       " 'anyhow',\n",
       " 'under',\n",
       " 'what',\n",
       " 'unless',\n",
       " 'latterly',\n",
       " 'wherein',\n",
       " 'not',\n",
       " 'quite',\n",
       " 'twelve',\n",
       " 'around',\n",
       " 'take',\n",
       " 'any',\n",
       " 'few',\n",
       " 'done',\n",
       " 'us',\n",
       " 'using',\n",
       " 'others',\n",
       " 'although',\n",
       " 'already',\n",
       " 'becoming',\n",
       " 'but',\n",
       " 'none',\n",
       " 'since',\n",
       " 'sometime',\n",
       " 'made',\n",
       " 'me',\n",
       " 'between',\n",
       " 'often',\n",
       " 'should',\n",
       " 'yourself',\n",
       " 'she',\n",
       " 'through',\n",
       " 'wherever',\n",
       " 'each',\n",
       " 'hereupon',\n",
       " 'give',\n",
       " 'nor',\n",
       " 'nevertheless',\n",
       " 'you',\n",
       " 'thru',\n",
       " 'who',\n",
       " 'does',\n",
       " 'our',\n",
       " 'besides',\n",
       " 'only',\n",
       " 'top',\n",
       " \"n't\",\n",
       " 'part',\n",
       " 'her',\n",
       " 'himself',\n",
       " 'has',\n",
       " 'hers',\n",
       " 'every',\n",
       " 'upon',\n",
       " 'too',\n",
       " '’ll',\n",
       " 'became',\n",
       " 'for',\n",
       " 'within',\n",
       " 'doing',\n",
       " 'own',\n",
       " 'had',\n",
       " 'nowhere',\n",
       " 'never',\n",
       " 'otherwise',\n",
       " 'show',\n",
       " 'nobody',\n",
       " 'beside',\n",
       " 'someone',\n",
       " 'off',\n",
       " 'formerly',\n",
       " 'three',\n",
       " \"'s\",\n",
       " 'namely',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'against',\n",
       " 'over',\n",
       " 'name',\n",
       " 'twenty',\n",
       " 'still',\n",
       " 'how',\n",
       " 'both',\n",
       " 'put',\n",
       " 'its',\n",
       " 'sixty',\n",
       " 'him',\n",
       " 'serious',\n",
       " 'most',\n",
       " 'either',\n",
       " 'among',\n",
       " 'throughout',\n",
       " 'together',\n",
       " 'ca',\n",
       " 'than',\n",
       " '’d',\n",
       " 'amongst',\n",
       " 'six',\n",
       " 'thereby',\n",
       " 'via',\n",
       " 'afterwards',\n",
       " 'were',\n",
       " 'call',\n",
       " \"'d\",\n",
       " '‘m',\n",
       " 'several',\n",
       " 'other',\n",
       " 'n’t',\n",
       " 'toward',\n",
       " 'much',\n",
       " 'due',\n",
       " 'moreover',\n",
       " 'full',\n",
       " 'one',\n",
       " 'might',\n",
       " '’s',\n",
       " 'hundred',\n",
       " 'without',\n",
       " 'hereafter',\n",
       " 'am',\n",
       " 'these',\n",
       " 'do',\n",
       " 'a',\n",
       " 'enough',\n",
       " 'did',\n",
       " 'must',\n",
       " 'herein',\n",
       " 'that',\n",
       " 'once',\n",
       " 'would',\n",
       " 'out',\n",
       " 'very',\n",
       " 'first',\n",
       " 'next',\n",
       " 'itself',\n",
       " 'some',\n",
       " 'ever',\n",
       " 'mostly',\n",
       " 'else',\n",
       " 'whereafter',\n",
       " 'get',\n",
       " 'from',\n",
       " 'n‘t',\n",
       " 'until',\n",
       " 'fifteen',\n",
       " 'another',\n",
       " 'to',\n",
       " 'such',\n",
       " 'forty',\n",
       " 'neither',\n",
       " 'rather',\n",
       " 'elsewhere',\n",
       " 'along',\n",
       " 'however',\n",
       " 'therein',\n",
       " 'so',\n",
       " 'can',\n",
       " 'sometimes',\n",
       " '’m',\n",
       " 'on',\n",
       " '’ve',\n",
       " 'also',\n",
       " 'whereas',\n",
       " 'when',\n",
       " 'become']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.extend(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.extend(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"wouldn't\", '“', '”', '...', \"''\", '’', '``', 'https', 'rt', '\\\\.+']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_punc = ['“','”','...',\"''\",'’','``','https','rt','\\.+']\n",
    "stopword_list.extend(additional_punc)\n",
    "stopword_list[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords and additional punctuation from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopped_tokenz = [word.lower() for word in tokenz if word.lower() not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sxsw', 9418),\n",
       " ('mention', 7120),\n",
       " ('link', 4313),\n",
       " ('google', 2593),\n",
       " ('ipad', 2432),\n",
       " ('apple', 2301),\n",
       " ('quot', 1696),\n",
       " ('iphone', 1516),\n",
       " ('store', 1472),\n",
       " ('2', 1114),\n",
       " ('new', 1090),\n",
       " ('austin', 959),\n",
       " ('amp', 836),\n",
       " ('app', 810),\n",
       " ('circles', 658),\n",
       " ('launch', 653),\n",
       " ('social', 647),\n",
       " ('android', 574),\n",
       " ('today', 574),\n",
       " ('network', 465),\n",
       " ('ipad2', 457),\n",
       " ('pop-up', 420),\n",
       " ('line', 405),\n",
       " ('free', 387),\n",
       " ('called', 361),\n",
       " ('party', 346),\n",
       " ('sxswi', 340),\n",
       " ('mobile', 338),\n",
       " ('major', 301),\n",
       " ('like', 290),\n",
       " ('time', 271),\n",
       " ('temporary', 264),\n",
       " ('opening', 257),\n",
       " ('possibly', 240),\n",
       " ('people', 226),\n",
       " ('downtown', 225),\n",
       " ('apps', 224),\n",
       " ('great', 222),\n",
       " ('maps', 219),\n",
       " ('going', 217),\n",
       " ('check', 216),\n",
       " ('mayer', 214),\n",
       " ('day', 214),\n",
       " ('open', 210),\n",
       " ('popup', 209),\n",
       " ('need', 205),\n",
       " ('marissa', 189),\n",
       " ('got', 185),\n",
       " ('w/', 182),\n",
       " ('know', 180)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = FreqDist(stopped_tokenz)\n",
    "freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize the Data and use Regex to find and remove URL's, Tags, other misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_misc = ['sxsw','mention',r'[a-zA-Z]+\\'?s]',r\"(http[s]?://\\w*\\.\\w*/+\\w+)\"\n",
    "                   ,r'\\#\\w*',r'RT [@]?\\w*:',r'\\@\\w*',r\"\\d$\",r\"^\\d\"\n",
    "                   ,r\"([a-zA-Z]+(?:'[a-z]+)?)\",r'\\d.',r'\\d','RT'] #[A-Z]{2,20} remove caps like MAGA and CDT\n",
    "stopword_list.extend(additional_misc)\n",
    "stopword_list.extend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_stopped_tokenz = [word.lower() for word in stopped_tokenz if word not in stopword_list]\n",
    "clean_lemmatized_tokenz = [lemmatizer.lemmatize(word.lower()) for word in stopped_tokenz if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_clean_lemma = FreqDist(clean_lemmatized_tokenz)\n",
    "freq_lemma = freq_clean_lemma.most_common(5000)\n",
    "freq_lemma2 = freq_clean_lemma.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count = len(clean_lemmatized_tokenz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_word_count = sum(freq_clean_lemma.values()) # just a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('link', 4324) ---- 5.004 %\n",
      "('google', 2594) ---- 3.002 %\n",
      "('ipad', 2432) ---- 2.814 %\n",
      "('apple', 2304) ---- 2.666 %\n",
      "('quot', 1696) ---- 1.963 %\n",
      "('iphone', 1516) ---- 1.754 %\n",
      "('store', 1511) ---- 1.749 %\n",
      "('new', 1090) ---- 1.261 %\n",
      "('austin', 960) ---- 1.111 %\n",
      "('amp', 836) ---- 0.967 %\n",
      "('app', 810) ---- 0.937 %\n",
      "('launch', 691) ---- 0.800 %\n",
      "('circle', 673) ---- 0.779 %\n",
      "('social', 647) ---- 0.749 %\n",
      "('android', 574) ---- 0.664 %\n",
      "('today', 574) ---- 0.664 %\n",
      "('network', 473) ---- 0.547 %\n",
      "('ipad2', 457) ---- 0.529 %\n",
      "('line', 442) ---- 0.512 %\n",
      "('pop-up', 422) ---- 0.488 %\n",
      "('free', 387) ---- 0.448 %\n",
      "('party', 386) ---- 0.447 %\n",
      "('called', 361) ---- 0.418 %\n",
      "('mobile', 340) ---- 0.393 %\n",
      "('sxswi', 340) ---- 0.393 %\n"
     ]
    }
   ],
   "source": [
    "for word in freq_lemma2:\n",
    "    normalized_freq = word[1] / lemma_word_count\n",
    "    print(word, \"----\", \"{:.3f}\".format(normalized_freq*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "\n",
    "# ## Initalize a WordCloud with our stopwords_list and no bigrams\n",
    "# wordcloud = WordCloud(stopwords=stopword_list,collocations=False)\n",
    "\n",
    "# ## Generate wordcloud from stopped_tokens\n",
    "# wordcloud.generate(','.join(clean_lemmatized_tokenz))\n",
    "\n",
    "# ## Plot with matplotlib\n",
    "# plt.figure(figsize = (12, 12), facecolor = None) \n",
    "# plt.imshow(wordcloud) \n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tweet_finder = nltk.BigramCollocationFinder.from_words(clean_lemmatized_tokenz)\n",
    "tweets_scored = tweet_finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(apple, store)</td>\n",
       "      <td>0.006920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(social, network)</td>\n",
       "      <td>0.005277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(new, social)</td>\n",
       "      <td>0.004837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(google, launch)</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(link, google)</td>\n",
       "      <td>0.003877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(network, called)</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(called, circle)</td>\n",
       "      <td>0.003634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(today, link)</td>\n",
       "      <td>0.003437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(major, new)</td>\n",
       "      <td>0.003356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(iphone, app)</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word      Freq\n",
       "0     (apple, store)  0.006920\n",
       "1  (social, network)  0.005277\n",
       "2      (new, social)  0.004837\n",
       "3   (google, launch)  0.003912\n",
       "4     (link, google)  0.003877\n",
       "5  (network, called)  0.003784\n",
       "6   (called, circle)  0.003634\n",
       "7      (today, link)  0.003437\n",
       "8       (major, new)  0.003356\n",
       "9      (iphone, app)  0.003333"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tweets_scored, columns=[\"Word\",\"Freq\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pmi_finder = nltk.BigramCollocationFinder.from_words(clean_lemmatized_tokenz)\n",
    "tweet_pmi_finder.apply_freq_filter(5)\n",
    "\n",
    "tweet_pmi_scored = tweet_pmi_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(û÷sxsw, goûª)</td>\n",
       "      <td>14.076983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(jc, penney)</td>\n",
       "      <td>13.813948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(knitted, staircase)</td>\n",
       "      <td>13.813948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(naomi, campbell)</td>\n",
       "      <td>13.813948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(parking, 5-10)</td>\n",
       "      <td>13.813948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(pauly, celebs)</td>\n",
       "      <td>13.813948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(98, accuracy)</td>\n",
       "      <td>13.591556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(aron, pilhofer)</td>\n",
       "      <td>13.591556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(charlie, sheen)</td>\n",
       "      <td>13.591556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(lynn, teo)</td>\n",
       "      <td>13.591556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Words        PMI\n",
       "0      (û÷sxsw, goûª)  14.076983\n",
       "1          (jc, penney)  13.813948\n",
       "2  (knitted, staircase)  13.813948\n",
       "3     (naomi, campbell)  13.813948\n",
       "4       (parking, 5-10)  13.813948\n",
       "5       (pauly, celebs)  13.813948\n",
       "6        (98, accuracy)  13.591556\n",
       "7      (aron, pilhofer)  13.591556\n",
       "8      (charlie, sheen)  13.591556\n",
       "9           (lynn, teo)  13.591556"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tweet_pmi_scored, columns=[\"Words\",\"PMI\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Uncertain</th>\n",
       "      <th>Negative</th>\n",
       "      <th>No Emotion</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Platform  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            Emotion  Uncertain  Negative  No Emotion  Positive  \n",
       "0  Negative emotion          0         1           0         0  \n",
       "1  Positive emotion          0         0           0         1  \n",
       "2  Positive emotion          0         0           0         1  \n",
       "3  Negative emotion          0         1           0         0  \n",
       "4  Positive emotion          0         0           0         1  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Positive_Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet            Platform  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            Emotion  Positive_Bin  \n",
       "0  Negative emotion             0  \n",
       "1  Positive emotion             1  \n",
       "2  Positive emotion             1  \n",
       "3  Negative emotion             0  \n",
       "4  Positive emotion             1  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = df1.drop(columns=['Uncertain','No Emotion'])\n",
    "# Turn negative and positive columns into one column of just negatives and positive.\n",
    "df1 = df1[df1['Emotion'] != \"No emotion toward brand or product\"]\n",
    "df1 = df1[df1['Emotion'] != \"I can't tell\"]\n",
    "# df1 = df1.drop(columns='Negative')\n",
    "df1 = df1.rename(columns={'Positive': 'Positive_Bin'})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3548 entries, 0 to 9088\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Tweet         3548 non-null   object\n",
      " 1   Platform      3191 non-null   object\n",
      " 2   Emotion       3548 non-null   object\n",
      " 3   Positive_Bin  3548 non-null   uint8 \n",
      "dtypes: object(3), uint8(1)\n",
      "memory usage: 114.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('link', 4324),\n",
       " ('google', 2594),\n",
       " ('ipad', 2432),\n",
       " ('apple', 2304),\n",
       " ('quot', 1696),\n",
       " ('iphone', 1516),\n",
       " ('store', 1511),\n",
       " ('new', 1090),\n",
       " ('austin', 960),\n",
       " ('amp', 836),\n",
       " ('app', 810),\n",
       " ('launch', 691),\n",
       " ('circle', 673),\n",
       " ('social', 647),\n",
       " ('android', 574),\n",
       " ('today', 574),\n",
       " ('network', 473),\n",
       " ('ipad2', 457),\n",
       " ('line', 442),\n",
       " ('pop-up', 422),\n",
       " ('free', 387),\n",
       " ('party', 386),\n",
       " ('called', 361),\n",
       " ('mobile', 340),\n",
       " ('sxswi', 340)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_lemma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1['Tweet']\n",
    "y = df1['Positive_Bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2661 (2661, 5362)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), X_train_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2661,)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.837279\n",
       "0    0.162721\n",
       "Name: Positive_Bin, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the two sets, lemmatized and not lemmatized using count vectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer.tokenize,\n",
    "                             stop_words=stopword_list,decode_error='ignore')\n",
    "tokenizer = nltk.TweetTokenizer(preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\":'[\", ':/', 'a-z', 'a-za-z', 'http', 'n', 'w', '‘'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "X_train_count = vectorizer.fit_transform(X_train)\n",
    "X_test_count = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(tokenizer=tokenizer.tokenize,\n",
    "                                    stop_words=stopword_list,decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf = tf_idf_vectorizer.fit_transform(X_train)\n",
    "X_test_tf_idf = tf_idf_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_for = RandomForestClassifier(class_weight='balanced')\n",
    "ran_for.fit(X_train_tf_idf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 5362 and input n_features is 2740 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-e67e7665f9c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_hat_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mran_for\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tf_idf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 5362 and input n_features is 2740 "
     ]
    }
   ],
   "source": [
    "y_hat_test = ran_for.predict(X_test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_token = TweetTokenizer()\n",
    "\n",
    "# pattern = r\"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "\n",
    "# for sentence in list(df['Tweet']):\n",
    "#     for word in str(sentence):\n",
    "#         word_tokenize(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = regexp_tokenize(','.join(str(v) for v in corpus), pattern=r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(stopped_tokenz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tweet_finder = nltk.BigramCollocationFinder.from_words(stopped_tokenz)\n",
    "tweets_scored = tweet_finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tweets_scored, columns=['Words','Freq']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation, numbers, uppercase letters, tags, #hashtags, stopwords, and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a function that takes a dataframe column input and cleans that column\n",
    "# def clean_column(i=(0,len(corpus)-1)):\n",
    "#     from nltk.corpus import stopwords\n",
    "#     import string\n",
    "#     from nltk import word_tokenize,regexp_tokenize\n",
    "    \n",
    "#     print(f\"- Tweet #{i}:\\n\")\n",
    "#     print(corpus[i],'\\n')\n",
    "#     tokens = word_tokenize(corpus[i])\n",
    "\n",
    "#     # Get all the stop words in the English language\n",
    "#     stopwords_list = stopwords.words('english')\n",
    "#     stopwords_list += list(nlp.Defaults.stop_words)\n",
    "#     stopwords_list += string.punctuation\n",
    "#     stopwords_list += additional_punc\n",
    "#     stopped_tokenz = [w.lower() for w in tokenz if w.lower() not in stopwords_list]\n",
    "    \n",
    "#     print(tokenz,end='\\n\\n')\n",
    "#     print(stopped_tokenz)\n",
    "                \n",
    "# # run function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_column(df['Tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(','.join(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
